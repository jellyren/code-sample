import numpy as np 
import pandas as pd 

df = pd.read_csv('data.txt', delimiter=' ') 
df.head() 
#install matmier library
!pip install matminer
from matminer.featurizers.conversions import StrToComposition
df = StrToComposition().featurize_dataframe(df, "comp")
df.head()
from matminer.featurizers.composition import ElementProperty

ep_feat = ElementProperty.from_preset(preset_name="magpie")
df = ep_feat.featurize_dataframe(df, col_id="composition")  # input the "composition" column to the featurizer
df.head()
from matminer.featurizers.conversions import CompositionToOxidComposition
from matminer.featurizers.composition import OxidationStates

df = CompositionToOxidComposition().featurize_dataframe(df, "composition", ignore_errors=True)

os_feat = OxidationStates()
df = os_feat.featurize_dataframe(df, "composition_oxid", ignore_errors=True)
df.head()
df.dropna(axis=0, how='any',inplace=True) 
df.describe() 

y = df['gfa{AM,AC,CR}'].values
excluded = ["comp", "gfa{AM,AC,CR}", "composition", "composition_oxid"]
X = df.drop(excluded, axis=1)
print("There are {} possible descriptors:\n\n{}".format(X.shape[1], X.columns.values))
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

y = pd.Categorical(y).codes 
X['comp'] = df['comp']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
train_formula = X_train['comp']
X_train = X_train.drop('comp', axis=1)
test_formula = X_test['comp']
X_test = X_test.drop('comp', axis=1)

rf_cla = RandomForestClassifier(n_estimators=31, max_depth=21, random_state=1)
rf_cla.fit(X_train, y_train)

print('training accuracy = ' + str(round(rf_cla.score(X_train, y_train), 3))) 
print('test accuracy = ' + str(round(rf_cla.score(X_test, y_test), 3))) 
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
score_lt = []

for i in range(0,200,10):
    rfc = RandomForestClassifier(n_estimators=i+1
                                ,random_state=1)
    rfc.fit(X_train, y_train)
    score = round(rfc.score(X_test, y_test), 3) 
    score_lt.append(score)
score_max = max(score_lt)
print('Maximum Accuracy：{}'.format(score_max),
      'Numbers of Subtrees：{}'.format(score_lt.index(score_max)*10+1))

x = np.arange(1,201,10)
plt.subplot(111)
plt.plot(x, score_lt, 'r-')
plt.show()
score_lt = []

for i in range(20,40):
    rfc = RandomForestClassifier(n_estimators=i
                                ,random_state=1)
    rfc.fit(X_train, y_train)
    score = round(rfc.score(X_test, y_test), 3) 
    score_lt.append(score)
score_max = max(score_lt)
print('Maximum Accuracy：{}'.format(score_max),
      'Numbers of Subtrees：{}'.format(score_lt.index(score_max)*10+1))

x = np.arange(20,40)
plt.subplot(111)
plt.plot(x, score_lt, 'o-')
plt.show()
# Build a random forest with 25 subtrees 
rfc = RandomForestClassifier(n_estimators=25, random_state=1)

# Use Grid Search to tune max_depth
param_grid = {'max_depth':np.arange(15,30)}
GS = GridSearchCV(rfc, param_grid, cv=10)
GS.fit(X_train, y_train)

best_param = GS.best_params_
best_score = GS.best_score_
print(best_param, best_score)
from sklearn.metrics import recall_score 
y_pred = rf_cla.predict(X_test) 
recall = recall_score(y_test, y_pred, average='macro') 
print('test recall = ' + str(round(recall, 3))) 
from sklearn.metrics import precision_score 
precision = precision_score(y_test, y_pred, average='macro') 
print('test precision = ' + str(round(precision, 3))) 
from sklearn.metrics import f1_score 
f1 = f1_score(y_test, y_pred, average='macro') 
print('test f1_score = ' + str(round(f1, 3))) 
from sklearn.neighbors import KNeighborsClassifier
classifier_KNN = KNeighborsClassifier(n_neighbors=1) 

classifier_KNN.fit(X_train, y_train)

print('training accuracy = ' + str(round(classifier_KNN.score(X_train, y_train), 3))) 
print('test accuracy = ' + str(round(classifier_KNN.score(X_test, y_test), 3))) 
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
figure(figsize=(8, 6), dpi=100)

importances = rf_cla.feature_importances_
included = X.columns.values
indices = np.argsort(importances)[::-1]
plt.bar(included[indices][0:10], importances[indices][0:10])
plt.xticks(rotation=30, ha='right')
